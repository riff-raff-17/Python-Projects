{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27af140a-83f9-444c-a48a-b6a0d2de6afd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How about you? How's your day going?\n",
      "\n",
      "Running model:llama3.2. Used time:1.2253990173339844s. Input speed:176.26911474919916letter/s\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "#使用的模型\n",
    "model=\"llama3.2\"\n",
    "\n",
    "#输入问题\n",
    "Q1_str=input(\"input_message:\")\n",
    "\n",
    "#记录模型开始思考的时间\n",
    "time0=time.time()\n",
    "response=ollama.chat(model,messages=[{\"role\":\"user\",\"content\":Q1_str,},])\n",
    "A1_str=response[\"message\"][\"content\"]\n",
    "\n",
    "#模型结束思考的时间\n",
    "time_AfterOutput=time.time()\n",
    "time_output=time_AfterOutput-time0\n",
    "v_output=len(A1_str)/time_output\n",
    "\n",
    "#打印输出\n",
    "print(A1_str)\n",
    "print()\n",
    "print(f\"Running model:{model}. Used time:{time_output}s. Input speed:{v_output}letter/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1807c18c-5a7b-4718-8f6d-c49deb57ee39",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m time_input=time_AfterInput-time0\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#计算输入速度\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m v_input=\u001b[38;5;28mlen\u001b[39m(\u001b[43minput_message\u001b[49m)/time_input\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#结果打印\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYour input:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.   Used time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.   Input speed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mletter/s\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'input_message' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#记录输入时间\n",
    "time0=time.time()\n",
    "time_AfterInput=time.time()\n",
    "time_input=time_AfterInput-time0\n",
    "\n",
    "#计算输入速度\n",
    "v_input=len(input_message)/time_input\n",
    "\n",
    "#结果打印\n",
    "print(f\"Your input:{len(input_message)}.   Used time:{time_input}.   Input speed{v_input}letter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecb787d-759f-4629-968b-70f2cfeee0b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m Q1_str=\u001b[33m\"\u001b[39m\u001b[33mhow are you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m response = ollama.chat(model=\u001b[33m'\u001b[39m\u001b[33mllama3.2\u001b[39m\u001b[33m'\u001b[39m,messages=[{\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m: Q1_str}],stream=\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m A1_str=\u001b[43mchunk\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(chunk[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m], end=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "#实时输出\n",
    "\n",
    "import ollama\n",
    "\n",
    "Q1_str=\"how are you \"\n",
    "\n",
    "response = ollama.chat(model='llama3.2',messages=[{'role': 'user', 'content': Q1_str}],stream=True,)\n",
    "\n",
    "A1_str=chunk[\"message\"][\"content\"]\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59f845a1-66c4-49fe-a0db-f9231abcf3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image contains text from a poem, which is William Shakespeare's Sonnet XVIII. Here are the words I can see:\n",
      "\n",
      "\"Shakespeare, Sonnet XVIII\n",
      "William Shakespeare\n",
      "Sonnet XVIII\n",
      "\n",
      "Shall I compare thee to a summer's day?\n",
      "Thou art more lovely and more temperate:\n",
      "Rough winds do shake the darling buds,\n",
      "And summer's lease hath all too short a span.\n",
      "The eye of heaven shall ne'er look like that;\n",
      "Nor all the sons of earth shine half so bright.\n",
      "How much more gilded than a sun that's high,\n",
      "Or decorated with Encelad's swift course?\n",
      "Two of the fairest persons living in this fair land,\n",
      "In their first ages were but two hours old;\n",
      "Yet saw they not as many winters' fall;\n",
      "Their purer wings see not the need to fly.\n",
      "They sing of summer and of spring;\n",
      "Of sunny morns, or joyful spring noons;\n",
      "As have I seen surpassing far their beauty's mark.\n",
      "And in these times have come my eyes,\n",
      "To witness and to praise to what end ye do it.\n",
      "So hail, great powers, for as in heaven,\n",
      "A day like this cannot be so long.\" \n",
      "\n",
      "Running model:llava. Used time:15.340827941894531s. Input speed:64.53367469798627letter/s\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "#使用的模型\n",
    "model=\"llava\"\n",
    "\n",
    "#输入照片\n",
    "time0=time.time()\n",
    "with open(\"poem.jpeg\",\"rb\") as file:\n",
    "    response=ollama.chat(model=\"llava\",messages=[{\"role\":\"user\",\"content\":\"what is this.Tell me all word you can see.\",\"images\":[file.read()],},],) \n",
    "\n",
    "A1_image=response[\"message\"][\"content\"]\n",
    "\n",
    "time_AfterOutput=time.time()\n",
    "\n",
    "#计算时间\n",
    "time_output=time_AfterOutput-time0\n",
    "v_output=len(A1_image)/time_output\n",
    "\n",
    "print(A1_image)\n",
    "print()\n",
    "print(f\"Running model:{model}. Used time:{time_output}s. Input speed:{v_output}letter/s\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcdf74b-a6fc-49df-b70b-7dbc7f32ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "你好！很高兴见到你，有什么我可以帮忙的吗？\n",
      "<\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "k\n",
      ">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<\n",
      "/\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "k\n",
      ">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "你\n",
      "好\n",
      "！\n",
      "很\n",
      "高\n",
      "兴\n",
      "见\n",
      "到\n",
      "你\n",
      "，\n",
      "有\n",
      "什\n",
      "么\n",
      "我\n",
      "可\n",
      "以\n",
      "帮\n",
      "忙\n",
      "的\n",
      "吗\n",
      "？\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "Q1_str=\"你好\"\n",
    "\n",
    "response=ollama.chat(model=\"deepseek-r1:14b\",messages=[{\"role\":\"user\",\"content\":Q1_str,},])\n",
    "\n",
    "A1_str=response[\"message\"][\"content\"]\n",
    "\n",
    "print(A1_str)\n",
    "\n",
    "for i in A1_str:\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc85e944-89b5-4525-9c9c-8c1b413cb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeca9241-ff82-4cbe-a0c1-2813a6f1bfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matchObj.group() :  Cats are smarter than \n",
      "matchObj.group(1) :  Cats\n",
      "matchObj.group(2) :  smarter than\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    " \n",
    "line = \"Cats are smarter than dogs\"\n",
    "# .* 表示任意匹配除换行符（\\n、\\r）之外的任何单个或多个字符\n",
    "# (.*?) 表示\"非贪婪\"模式，只保存第一个匹配到的子串\n",
    "matchObj = re.match( r'(.*) are (.*) ', line)\n",
    " \n",
    "if matchObj:\n",
    "   print (\"matchObj.group() : \", matchObj.group())\n",
    "   print (\"matchObj.group(1) : \", matchObj.group(1))\n",
    "   print (\"matchObj.group(2) : \", matchObj.group(2))\n",
    "else:\n",
    "   print (\"No match!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4941f551-f1bd-4e78-a4cf-77163762224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500cf3d6-c12a-4102-8e56-d92b80e3019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的翻译结果:\n",
      "你好你好 你怎么样了？\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_translation(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    提取输入文本中 </think> 标签后面的翻译结果。\n",
    "    如果找不到 </think> 标签，则返回原文本（或根据需要调整）。\n",
    "    \"\"\"\n",
    "    # 正则表达式：匹配 </think> 标签后紧跟的所有内容（包括换行符），并提取第一行非空文本\n",
    "    pattern = r'</think>\\s*(.+)'\n",
    "    match = re.search(pattern, input_text, flags=re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        # 若没有找到 </think> 标签，则可以直接返回原文本或做其他处理\n",
    "        return input_text.strip()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_input = \"\"\"输入：Hello hello how are you\n",
    "<think>\n",
    "好，用户让我把“Hello hello how are you”翻译成中文，并且只要翻译的结果。首先，我需要确认这句话的意思。“Hello hello”是重复问候，可能表达急切或强调，而“how are you”是常见的问候语。\n",
    "\n",
    "接下来，我得考虑如何准确地翻译。直接翻译的话，“你好你好 你怎么样了？”这样会比较直译，但中文里通常不会在口语中连续用两个“你好”，所以是否需要调整呢？不过用户要求只输出翻译结果，不需要加额外解释，所以我保持原样。\n",
    "\n",
    "再检查一下语法和语感。“你好你好”听起来有点重复，但在表达急切时是可以接受的。而“you”的翻译是“你”。整体来看，“你好你好 你怎么样了？”这句话在中文里是通顺的，符合用户的要求。\n",
    "</think>\n",
    "\n",
    "你好你好 你怎么样了？\"\"\"\n",
    "    \n",
    "    # 提取并输出翻译结果\n",
    "    translation = extract_translation(sample_input)\n",
    "    print(\"提取的翻译结果:\")\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a0d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
